# -*- coding: utf-8 -*-
"""PRML_Lab1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19KrXwq8V9DLVu3E0xYLkr1RgrB1hSRfD
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Problem 1 """

# a) Converting File Data to a list.

file = ('/content/drive/My Drive/Colab Notebooks/1a.txt') 
file_data = open(file, "r")
data = file_data.readlines()
file_data.close()
new = []
for i in data:
    i = i.strip("\n")
    new.append(i)
print(new)

# b) Converting User Input to a number.

user_input = input("Enter a number: ")
try:
    user_input = int(user_input)
    print(type(user_input)," is the type of ", user_input)
except ValueError:
    print("Error: Not a number")

# c) Converting string to Datetime.

import datetime
string = "2022-Jan-14 12:03:40"
try:
    print("Initial string: ", string)   
    datetime_object = datetime.datetime.strptime(string, '%Y-%b-%d %H:%M:%S')
    print("Converted datetime format: ", datetime_object)
except ValueError:
    print("Error: Not a valid date")

# d) Calling external commands

import subprocess

# Commenting out the below two commands because they can only run on a local environment on a PC
# return_code = subprocess.call(['ping', 'localhost'])
# print("Output of call() : ", return_code)

# e) Counting the occurances of a list item

L = ["apple","mango","banana","apple","orange","banana","mango"]
print(*L, sep=", ")
val = input("Enter the value to be counted: ")
print(val, "has occured",L.count(val),"times in the list.")

# f) Flattening List using recurrsion

L = [[1, 2, [3,0,2]], [4, 5, 6, 7, 8, 9]]

def flatten_list(L):
    
    for i in L:
        if type(i)== list:
            flatten_list(i)
        else:
            print(i,end=' ')
    
flatten_list(L)

# g) Merging Dictionaries 

dict1 = { 'a': 1, 'b': 2, 'c': 3 }
dict2 = {'d': 4, 'e': 5, 'f': 6 }

dict1.update(dict2)
print(dict1)

# h) Removing Duplicate Items from a list

L = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
L = list(set(L))
print(L)

# i) Script to check whether a given key already exists in a dictionary


dict1 = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5}
val = input("Enter the key to check: ")
if val in dict1:
    print("Key exists in the dictionary")
else:
    print("Key does not exist in the dictionary")

"""## Problem 2"""

import numpy as np

matrix1 = np.array([[1,2,3],[5,6,7],[9,10,11]])
matrix2 = np.array([[4,3,2],[8,7,6],[12,11,10]])

matrix1

matrix2

# a) Displaying first row of first matrix

print("First row of first matrix:",matrix1[0])

# b) Displaying second column of second matrix

print("Second column of second matrix: ",matrix2[:,1])

# c) Performing Matrix Multiplication

def matrix_multiplication(matrix1,matrix2):
    if matrix1.shape[1] != matrix2.shape[0]:
        return None
    else:
        return np.dot(matrix1,matrix2)
print("Matrix multiplication of the two matrices will be: \n",matrix_multiplication(matrix1,matrix2))

# d) Performing Element-wise Multiplication

print("Element-wise multiplication of the two matrices would be: ")
print(np.multiply(matrix1,matrix2))

# e) Performing dot product between each column of first matrix and each column of second matrix

ans = []
for i in range(0,3):
    sum = 0
    for j in range(0,3):
        sum += matrix1[j][i] * matrix2[j][i]
    ans.append(sum)

print("The dot product between each column of first matrix and each column of second matrix is:",ans)

"""## Problem 3

i) Assigning a type to each of the following features
       a) Model - Nominal Scale
       b) Type - Ordinal
       c) Max. Price - Ratio
       d) Airbags - Nominal Scale
"""

import pandas as pd
import numpy as np

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Cars93.csv')

df

df.describe()

# ii) Function to handle the missing values in the dataset (e.g., any NA, NaN values).
def handle_missing_values(df):
  missing_columns = df.loc[:,df.isnull().any()].columns
  for col in missing_columns:
    df[col].fillna(df[col].mean(), inplace=True)
    return df

handle_missing_values(df)

df.info()   #Below info shows no null values present after handling the missing values.

# iii) Function to reduce noise (any error in the feature) in individual attributes.

# For handling noise in the feature Model.
for i in range(len(df.loc[:,['Model']])):
    try:
        row = i
        var = int(df["Model"][row])
        # print(var)
        # print(i)
        df.drop([i], axis=0,inplace=True)
    except:
        continue
df.reset_index(drop=True, inplace=True)
print("After reducing noise: \n", df["Model"])

# For Handling noise in the feature Cylinders

ind = df.index[df["Cylinders"] == 'rotary']         
df.drop(axis=0, index=ind, inplace= True)
np.unique(df["Cylinders"])

# iv) Function to encode all the categorical features in the dataset according to the type of variable jointly.
from sklearn.preprocessing import LabelEncoder
prog = LabelEncoder()
unencoded = []

def encode_categorical_features(df):
    
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = prog.fit_transform(df[col])
        else:
            unencoded.append(col)
    return df

df = encode_categorical_features(df)

df

print(unencoded)

# v) Function to normalize / scale the features either individually or jointly.

from sklearn.preprocessing import StandardScaler
scalar = StandardScaler()

def normalizing_features(df):
    columns = unencoded        
    for col in columns:
        df[col] = scalar.fit_transform(df[[col]])                               
    return df

df = normalizing_features(df)

df

# vi) Function to create a random split of the data into train, validation and test sets in the ratio of [70:20:10].

from sklearn.model_selection import train_test_split

X = df.drop(['Price'], axis=1).copy()
y = df['Price']

X_train , X_extra, y_train, y_extra = train_test_split(X, y, train_size=0.7)

X_validation, X_test, y_validation, y_test = train_test_split(X_extra, y_extra, train_size=0.67)

print(X_train.shape), print(y_train.shape)
print(X_validation.shape), print(y_validation.shape)
print(X_test.shape), print(y_test.shape)

"""## Problem 4"""

import matplotlib.pyplot as plt
import numpy as np
import math

# a) Plotting y = 5x + 4 where x ranges from [-10, 10].

x = np.linspace(-10, 10, 100)
y = (x * 5) + 4
plt.plot(x, y, '-r')
plt.title('Plot of y = 5x + 4')
plt.xlabel('x')
plt.ylabel('y')
plt.grid()
plt.show()

# b) Plotting y = ln(x) where x > 10 and x < 100.

x = np.linspace(10, 100, 100)
y = [math.log(k) for k in x]
plt.plot(x, y, '-r')
plt.title('Plot of y = ln(x) ')
plt.xlabel('x')
plt.ylabel('y')
plt.grid()
plt.show()

# c) Plotting y = x^2 where x ranges from [-10, 10].

x = np.linspace(-10, 10, 100)
y = x**2
plt.plot(x, y, '-r')
plt.title('Plot of y = x^2 ')
plt.xlabel('x')
plt.ylabel('y')
plt.grid()
plt.show()

"""#Problem 5

# Import the Necessary Python Libraries and Components
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split as tts
from sklearn.linear_model import LogisticRegression as LR
from sklearn.tree import DecisionTreeClassifier as DTC
from sklearn.metrics import confusion_matrix as cm
from sklearn.metrics import precision_score as ps
from sklearn.metrics import recall_score as rs
from sklearn.metrics import f1_score as f1s
from sklearn.metrics import accuracy_score as acc

"""### To Disable Convergence Warnings (For Custom Training)"""

from warnings import simplefilter
from sklearn.exceptions import ConvergenceWarning
simplefilter("ignore", category=ConvergenceWarning)

"""# 1.) Input the Dataset"""

# Dataset Reference :- https://www.kaggle.com/uciml/breast-cancer-wisconsin-data

data = pd.read_csv("/content/drive/My Drive/Colab Notebooks/data.csv")
data

"""# 2.) Convert the String Labels into easily-interpretable Numerics"""

# Note :- There are many existing Encoders for converting String to Numeric Labels, but for convenience, we used Pandas.

condition_M = data.diagnosis == "M"
condition_B = data.diagnosis == "B"

data.loc[condition_M,"diagnosis"]=0
data.loc[condition_B,"diagnosis"]=1

data

"""# 3.) Converting Dataframe into Numpy Arrays (Features and Labels)"""

Y = data.diagnosis.to_numpy().astype('int')                                     # Labels

X_data = data.drop(columns=["id","diagnosis","Unnamed: 32"])
X = X_data.to_numpy()                                                           # Input Features

"""# 4.) Splitting the Dataset into Train and Test Portions"""

user_prompt = 0.3
user_enable = False

x_train,x_test,y_train,y_test = tts(X,Y,test_size=user_prompt,shuffle=user_enable)

"""# 5.) Model Training and Predicting"""

# Note :- Don't worry about the code snippet here, it is just to produce the predictions for the test data portion of each classifier

logistic_model = LR()
logistic_model.fit(x_train,y_train)
logistic_pred = logistic_model.predict(x_test)

decision_model = DTC()
decision_model.fit(x_train,y_train)
decision_pred = decision_model.predict(x_test)

"""# 6.) Evaluation Metrics (Inbulit v/s Scaratch)

## Confusion Matrix
"""

inbuilt_matrix_logistic = cm(y_test,logistic_pred)
inbuilt_matrix_decision = cm(y_test,decision_pred)

print("Confusion Matrix for Logistic Regression-based Predictions =>")
print(inbuilt_matrix_logistic)
print("Confusion Matrix for Decision Tree-based Predictions =>")
print(inbuilt_matrix_decision)

def confusion_matrix(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = np.array([[true_negative_class, false_positive_class],[false_negative_class, true_positive_class]])  
  return ans
confusion_matrix_logistic = confusion_matrix(y_test, logistic_pred)
confusion_matrix_decision = confusion_matrix(y_test, decision_pred)

print("Confusion Matrix for Logistic Regression-based Predictions from Scratch: \n", confusion_matrix_logistic)
print("Confusion Matrix for Decision Tree-based Predictions from Scratch: \n", confusion_matrix_decision)

"""## Average Accuracy"""

inbuilt_acc_logistic = acc(y_test,logistic_pred)
inbuilt_acc_decision = acc(y_test,decision_pred)

print("Accuracy for Logistic Regression-based Predictions =>",str(inbuilt_acc_logistic*100)+"%")
print("Accuracy for Decision Tree-based Predictions =>",str(inbuilt_acc_decision*100)+"%")

def avg_accuracy(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = (true_negative_class + true_positive_class)/(true_positive_class + true_negative_class + false_negative_class + false_positive_class)
  return ans
avg_accuracy_logistic = avg_accuracy(y_test, logistic_pred) * 100
avg_accuracy_decision = avg_accuracy(y_test, decision_pred) * 100

print("Average Accuracy for Logistic Regression-based Predictions from Scratch: \n", avg_accuracy_logistic, "%")
print("Average Accuracy for Decision Tree-based Predictions from Scratch: \n", avg_accuracy_decision, "%")

"""## Precision"""

inbuilt_ps_logistic = ps(y_test,logistic_pred)
inbuilt_ps_decision = ps(y_test,decision_pred)

print("Precision for Logistic Regression-based Predictions =>",str(inbuilt_ps_logistic*100)+"%")
print("Precision for Decision Tree-based Predictions =>",str(inbuilt_ps_decision*100)+"%")

def precision(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = (true_positive_class)/(true_positive_class + false_positive_class)
  return ans
precision_logistic = precision(y_test, logistic_pred) * 100
precision_decision = precision(y_test, decision_pred) * 100

print("Precision for Logistic Regression-based Predictions from Scratch: \n", precision_logistic, "%")
print("Precision for Decision Tree-based Predictions from Scratch: \n", precision_decision, "%")

"""## Recall"""

inbuilt_rs_logistic = rs(y_test,logistic_pred)
inbuilt_rs_decision = rs(y_test,decision_pred)

print("Recall for Logistic Regression-based Predictions =>",str(inbuilt_rs_logistic*100)+"%")
print("Recall for Decision Tree-based Predictions =>",str(inbuilt_rs_decision*100)+"%")

def recall(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = (true_positive_class)/(true_positive_class + false_negative_class)
  return ans
recall_logistic = recall(y_test, logistic_pred) * 100
recall_decision = recall(y_test, decision_pred) * 100

print("Recall for Logistic Regression-based Predictions from Scratch: \n", recall_logistic, "%")
print("Recall for Decision Tree-based Predictions from Scratch: \n", recall_decision, "%")

"""## F-1 Score"""

inbuilt_f1s_logistic = f1s(y_test,logistic_pred)
inbuilt_f1s_decision = f1s(y_test,decision_pred)

print("F1-Score for Logistic Regression-based Predictions =>",str(inbuilt_f1s_logistic*100)+"%")
print("F1-Score for Decision Tree-based Predictions =>",str(inbuilt_f1s_decision*100)+"%")

def f1_score(precision, recall):
  recp = (1/(precision))+(1/(recall))
  ans = 2/recp
  return ans
  
f1_score_logistic = f1_score(precision_logistic, recall_logistic) 
f1_score_decision = f1_score(precision_decision, recall_decision) 

print("F1 Score for Logistic Regression-based Predictions from Scratch: \n", f1_score_logistic, "%")
print("F1 Score for Decision Tree-based Predictions from Scratch: \n", f1_score_decision, "%")

"""## Class-Wise Accuracy"""

def class_wise_accuracy(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans1 = (true_negative_class)/(true_negative_class + false_positive_class)
  ans2 = (true_positive_class)/(true_positive_class + false_negative_class)
  ans = (ans1 + ans2) / 2
  return ans
class_wise_accuracy_logistic = class_wise_accuracy(y_test, logistic_pred) * 100
class_wise_accuracy_decision = class_wise_accuracy(y_test, decision_pred) * 100

print("Class Wise Accuracy for Logistic Regression-based Predictions from Scratch: \n", class_wise_accuracy_logistic, "%")
print("Class Wise Accuracy for Decision Tree-based Predictions from Scratch: \n", class_wise_accuracy_decision, "%")

"""## Sensitivity"""

def sensitivity(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = (true_positive_class)/(true_positive_class + false_negative_class)
  return ans
sensitivity_logistic = sensitivity(y_test, logistic_pred) * 100
sensitivity_decision = sensitivity(y_test, decision_pred) * 100

print("Sensitivity for Logistic Regression-based Predictions from Scratch: \n", sensitivity_logistic, "%")
print("Sensitivity for Decision Tree-based Predictions from Scratch: \n", sensitivity_decision, "%")

"""## Specificity"""

def specificity(test, pred):
  true_positive_class = 0
  true_negative_class = 0
  false_positive_class = 0
  false_negative_class = 0
  for i in range(0,len(pred)):
    if pred[i] == test[i]:
      if pred[i] == 1:
        true_positive_class += 1
      elif pred[i] == 0:
        true_negative_class += 1
    elif pred[i] != test[i]:
      if pred[i] == 1:
        false_positive_class += 1
      elif pred[i] == 0:
        false_negative_class += 1    
  ans = (true_negative_class)/(true_negative_class + false_positive_class)
  return ans
specificity_logistic = specificity(y_test, logistic_pred) * 100
specificity_decision = specificity(y_test, decision_pred) * 100

print("Specificity for Logistic Regression-based Predictions from Scratch: \n", specificity_logistic, "%")
print("Specificity for Decision Tree-based Predictions from Scratch: \n", specificity_decision, "%")