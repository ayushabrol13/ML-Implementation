# -*- coding: utf-8 -*-
"""B20AI052.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10p6swdgCOrbu6CTxzXITFSYxju_Zzu-k

Question 1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""From the given link, download “anneal.data”, “anneal.names” and 
“anneal.test”, convert them into a readable format (Ex: txt, csv, etc....) and do meaningful Exploratory Data Analysis.
"""

df_train = pd.read_csv("anneal.data", header=None)
df_test = pd.read_csv("anneal.test", header=None)
df_train.columns = ["family", "product-type", "steel", "carbon", "hardness", "temper_rolling", "condition", "formability", "strength", "non-ageing", "surface-finish", "surface-quality", "enamelability", "bc", "bf", "bt", "bw/me", "bl", "m" , "chrom", "phos", "cbond", "marvi", "exptl", "ferro", "corr", "blue/bright/varn/clean", "lustre", "jurofm", "s", "p", "shape", "thick", "width", "len", "oil", "bore", "packing", "classes"]
df_test.columns = ["family", "product-type", "steel", "carbon", "hardness", "temper_rolling", "condition", "formability", "strength", "non-ageing", "surface-finish", "surface-quality", "enamelability", "bc", "bf", "bt", "bw/me", "bl", "m" , "chrom", "phos", "cbond", "marvi", "exptl", "ferro", "corr", "blue/bright/varn/clean", "lustre", "jurofm", "s", "p", "shape", "thick", "width", "len", "oil", "bore", "packing", "classes"]

df_train

df_test

"""Preprocess the data (If any discrepancies/errors, handle them as well) and split the data into [65:35]."""

all_cols = list(df_train.columns)
dropping_cols = []
for i in all_cols:
    values, counts = np.unique(df_train[i], return_counts=True)
    values = list(values)
    if '?' in values:
        idx = values.index('?')
        if(counts[idx] >= 200):
            dropping_cols.append(i)

print("Columns that can be dropped are: ", dropping_cols)

for i in dropping_cols:
    df_train = df_train.drop(i, axis=1)
    df_test = df_test.drop(i, axis=1)

df_train

df_test

all_cols = list(df_train.columns)
print(all_cols)
for i in all_cols:
    values, counts = np.unique(df_train[i], return_counts=True)
    values = list(values)
    if '?' in values:
        idx = values.index('?')
        print(i, counts[idx])
    else:
        print(i, 0)

df_train = df_train.drop(['steel'] , axis=1)
df_test = df_test.drop(['steel'] , axis=1)
df_train.head()

df_test.head()

cont_data = ['carbon', 'hardness', 'strength', 'thick', 'width', 'len']
cat_data = ['product-type', 'shape', 'bore']

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_train[cont_data] = scaler.fit_transform(df_train[cont_data])
df_test[cont_data] = scaler.fit_transform(df_test[cont_data])

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for i in cat_data:
    df_train[i] = le.fit_transform(df_train[i])
    df_test[i] = le.fit_transform(df_test[i])

from sklearn.model_selection import train_test_split
train_data, val_data = train_test_split(df_train, test_size=0.35, random_state=42)

train_data

val_data

df_test

"""Train 2-3 Classification Models (studied and implemented so far) with the proper reasoning of choosing them and show 5-Fold Cross-Validation Plots as well for comparison."""

train_attributes = train_data.drop(['classes'], axis=1)
train_classes = train_data['classes']
val_attributes = val_data.drop(['classes'], axis=1)
val_classes = val_data['classes']
test_attributes = df_test.drop(['classes'], axis=1)
test_classes = df_test['classes']

def cross_val_score(model, test_att, test_class, k):
    scores = []
    for i in range(k):
        train_att, val_att, train_class, val_class = train_test_split(test_att, test_class, test_size=0.5)
        model.fit(train_att, train_class)
        scores.append(model.score(val_att, val_class))
    return scores

def plotting_cross_val_scores(y_pred, val_classes):
    fig, ax = plt.subplots()
    ax.scatter(val_classes, y_pred, edgecolors=(0, 0, 0))
    ax.plot([val_classes.min(), val_classes.max()], [val_classes.min(), val_classes.max()], "k--", lw=4)
    ax.set_xlabel("Measured")
    ax.set_ylabel("Predicted")
    plt.show()

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)
rfc.fit(train_attributes, train_classes)
y_pred_rfc_val_bpca = rfc.predict(val_attributes)
print("For validation data:", cross_val_score(rfc, val_attributes, val_classes, 5))
plotting_cross_val_scores(y_pred_rfc_val_bpca, val_classes)

rfc.fit(train_attributes, train_classes)
y_pred_rfc_test_bpca = rfc.predict(test_attributes)
print("For testing data:", cross_val_score(rfc, test_attributes, test_classes, 5))
plotting_cross_val_scores(y_pred_rfc_test_bpca, test_classes)

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier(max_depth=10, random_state=0)
dtc.fit(train_attributes, train_classes)
y_pred_dtc_val_bpca = dtc.predict(val_attributes)
print("For validation data:", cross_val_score(dtc, val_attributes, val_classes, 5))
plotting_cross_val_scores(y_pred_dtc_val_bpca , val_classes)

dtc.fit(train_attributes, train_classes)
y_pred_dtc_test_bpca  = dtc.predict(test_attributes)
print("For testing data:", cross_val_score(dtc, test_attributes, test_classes, 5))
plotting_cross_val_scores(y_pred_dtc_test_bpca , test_classes)

from sklearn.ensemble import BaggingClassifier

bc = BaggingClassifier(n_estimators=100, max_samples=0.5, max_features=0.5, random_state=0)
bc.fit(train_attributes, train_classes)
y_pred_bc_val_bpca  = bc.predict(val_attributes)
print("For validation data", cross_val_score(bc, val_attributes, val_classes, 5))
plotting_cross_val_scores(y_pred_bc_val_bpca , val_classes)

bc.fit(train_attributes, train_classes)
y_pred_bc_test_bpca  = bc.predict(test_attributes)
print("For testing data", cross_val_score(bc, val_attributes, val_classes, 5))
plotting_cross_val_scores(y_pred_bc_test_bpca , test_classes)

train_attributes

"""Implement Principal Component Analysis from scratch, with sub-tasks as following:

a. Centralize the Data via feature-wise means and standard deviations.  Write the code for deriving the covariance matrix from scratch.
b. Make a function Singular_Value_Decomp from scratch in order to compute
Eigenvectors, Eigenvalues and Principal Components.
"""

X_covariance_mat = np.cov(train_attributes, rowvar=False)
X_covariance_mat

eig_vals, eig_vecs = np.linalg.eig(X_covariance_mat)

print('Eigenvectors are\n%s' %eig_vecs)
print('\nEigenvalues corresponding to eigen vectors are\n%s' %eig_vals)

eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i], i) for i in range(len(eig_vals))]

eig_pairs.sort(key=lambda x: x[0], reverse=True)

print('Eigenvalues in descending order:')
for i in eig_pairs:
    print(i[0])

tot = sum(eig_vals)
var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]
cum_var_exp = np.cumsum(var_exp)
print("Variance captured by each component is \n",var_exp)
print(60 * '-')
print("Cumulative variance captured as we travel each component \n",cum_var_exp)

def plotting_scree_plot(eig_pairs):
    fig, ax = plt.subplots()
    ax.bar(range(1,len(eig_pairs)+1), var_exp, alpha=0.5, align='center',
           label='individual explained variance')
    ax.step(range(1,len(eig_pairs)+1), cum_var_exp, where='mid',
            label='cumulative explained variance')
    ax.set_ylabel('Explained variance ratio')
    ax.set_xlabel('Principal components')
    ax.set_xticks(range(1,len(eig_pairs)+1))
    ax.legend(loc='best')
    plt.show()

plotting_scree_plot(eig_pairs)

train_attributes

print("All Eigen Values along with Eigen Vectors")
for i in range(len(eig_pairs)):
    print("Eigenvalue:", eig_pairs[i][0])
    print("Eigenvector:", list(eig_pairs[i][1]))
    print("Feature Number: ", eig_pairs[i][2])
    print(40 * '-')

matrix_final2 = np.hstack((eig_pairs[0][1].reshape(9,1), eig_pairs[1][1].reshape(9,1)))

matrix_final3 = np.hstack((matrix_final2, eig_pairs[2][1].reshape(9,1)))

matrix_final4 = np.hstack((matrix_final3, eig_pairs[3][1].reshape(9,1)))

matrix_final5 = np.hstack((matrix_final4, eig_pairs[4][1].reshape(9,1)))

matrix_final6 = np.hstack((matrix_final5, eig_pairs[5][1].reshape(9,1)))
matrix_final6

train_attributes_a = train_attributes.dot(matrix_final6)
print("Training Set after PCA: ")
train_attributes_a

val_attributes_a = val_attributes.dot(matrix_final6)
print("Validation Set after PCA: ")
val_attributes_a

test_attributes_a = test_attributes.dot(matrix_final6)
print("Test Set after PCA: ")
test_attributes_a

import seaborn as sb
import matplotlib.pyplot as plt
 
plt.figure(figsize = (6,6))
sb.heatmap(matrix_final6, xticklabels = ['PC1', 'PC2'], yticklabels = ['PC1', 'PC2'], annot = True, fmt = '.2f', linewidths = .5)

"""Use the above-made PCA to reduce the data upto a chosen dimension/principal-components and train 2-3 chosen classification models alongside 5-Fold Cross-Validation Plots."""

rfc2 = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)
rfc2.fit(train_attributes_a, train_classes)
y_pred_rfc_val_apca = rfc2.predict(val_attributes_a)
print("For validation data:", cross_val_score(rfc2, val_attributes_a, val_classes, 5))
plotting_cross_val_scores(y_pred_rfc_val_apca, val_classes)

rfc2.fit(train_attributes_a, train_classes)
y_pred_rfc_test_apca = rfc2.predict(test_attributes_a)
print("For testing data:", cross_val_score(rfc2, test_attributes_a, test_classes, 5))
plotting_cross_val_scores(y_pred_rfc_test_apca, test_classes)

from sklearn.tree import DecisionTreeClassifier

dtc2 = DecisionTreeClassifier(max_depth=10, random_state=0)
dtc2.fit(train_attributes_a, train_classes)
y_pred_dtc_val_apca  = dtc2.predict(val_attributes_a)
print("For validation data:", cross_val_score(dtc2, val_attributes_a, val_classes, 5))
plotting_cross_val_scores(y_pred_dtc_val_apca, val_classes)

dtc2.fit(train_attributes_a, train_classes)
y_pred_dtc_test_apca = dtc2.predict(test_attributes_a)
print("For testing data:", cross_val_score(dtc2, test_attributes_a, test_classes, 5))
plotting_cross_val_scores(y_pred_dtc_test_apca, test_classes)

from sklearn.ensemble import BaggingClassifier

bc2 = BaggingClassifier(n_estimators=100, max_samples=0.5, max_features=0.5, random_state=0)
bc2.fit(train_attributes_a, train_classes)
y_pred_bc_val_apca = bc2.predict(val_attributes_a)
print("For validation data", cross_val_score(bc2, val_attributes_a, val_classes, 5))
plotting_cross_val_scores(y_pred_bc_val_apca, val_classes)

bc2.fit(train_attributes_a, train_classes)
y_pred_bc_test_apca = bc2.predict(test_attributes_a)
print("For testing data", cross_val_score(bc2, test_attributes_a, test_classes, 5))
plotting_cross_val_scores(y_pred_bc_test_apca, test_classes)

"""Show the Test results of Classification Models on both types of datasets (Before and After PCA), via 2-3 Evaluation Metrics of choice (Ex:- Accuracy, Sensitivity, F1-Score, etc.) with the proper
reasonings.
"""

from sklearn.metrics import f1_score

print("Before PCA F1 Scores were: \n")
print("For Random Forest Classifier: ", f1_score(test_classes, y_pred_rfc_test_bpca, average='weighted'))
print("For Decision Tree Classifier: ", f1_score(test_classes, y_pred_dtc_test_bpca, average='weighted'))
print("For Bagging Classifier: ", f1_score(test_classes, y_pred_bc_test_bpca, average='weighted'))

print(40 * '-')
print("\n After PCA F1 Scores were: \n")
print("For Random Forest Classifier: ", f1_score(test_classes, y_pred_rfc_test_apca, average='weighted'))
print("For Decision Tree Classifier: ", f1_score(test_classes, y_pred_dtc_test_apca, average='weighted'))
print("For Bagging Classifier: ", f1_score(test_classes, y_pred_bc_test_apca, average='weighted'))

"""Were any changes observed before and after implementing PCA, with respect to the distribution of the dataset? """

from sklearn.metrics import accuracy_score

print("Before PCA Accuracy was: \n")
print("For Random Forest Classifier: ", accuracy_score(test_classes, y_pred_rfc_test_bpca))
print("For Decision Tree Classifier: ", accuracy_score(test_classes, y_pred_dtc_test_bpca))
print("For Bagging Classifier: ", accuracy_score(test_classes, y_pred_bc_test_bpca))

print(40 * '-')
print("\n After PCA Accuracy was: \n")
print("For Random Forest Classifier: ", accuracy_score(test_classes, y_pred_rfc_test_apca))
print("For Decision Tree Classifier: ", accuracy_score(test_classes, y_pred_dtc_test_apca))
print("For Bagging Classifier: ", accuracy_score(test_classes, y_pred_bc_test_apca))

"""Also, make any suitable graph through which the optimal number of
principal components can be decided for optimal results.
"""

def optimal_number_of_principal_components(train_attributes, train_classes, val_attributes, val_classes, test_attributes, test_classes):
    """
    This function calculates the optimal number of principal components
    for PCA. The function takes in the training, validation and testing
    data and class labels and returns the optimal number of principal
    components.
    """
    global matrix_final2
    global matrix_final3
    global matrix_final4
    global matrix_final5
    global matrix_final6
    global eig_pairs

    pred_val = []
    pred_test = []

    L = [matrix_final2, matrix_final3, matrix_final4, matrix_final5, matrix_final6]
    for i in range(0,len(L)):
        new_train = train_attributes.dot(L[i])
        new_val = val_attributes.dot(L[i])
        new_test = test_attributes.dot(L[i])
        model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)
        model.fit(new_train, train_classes)
        y_pred_rfc_val = model.predict(new_val)
        y_pred_rfc_test = model.predict(new_test)
        y_pred_rfc_val_acc = accuracy_score(val_classes, y_pred_rfc_val)
        y_pred_rfc_test_acc = accuracy_score(test_classes, y_pred_rfc_test)
        pred_val.append(y_pred_rfc_val_acc)
        pred_test.append(y_pred_rfc_test_acc)
        
    #Plot between PCA Components and accuracies
    plt.plot(range(2,7), pred_val, 'bo-', label='Validation Accuracy')
    plt.plot(range(2,7), pred_test, 'ro-', label='Testing Accuracy')
    plt.xlabel('Number of Principal Components')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs Number of Principal Components')
    plt.legend()
    plt.show()

optimal_number_of_principal_components(train_attributes, train_classes, val_attributes, val_classes, test_attributes, test_classes)

"""Question 2

Implement Linear Discriminant Analysis from scratch with the following subtasks:-
a. A function for computing within class and between class scatter matrices
b. A function that will automatically select the number of linear discriminants based upon the percentage of variance that needs to be conserved.
"""

class LDA:
    def __init__(self, n_components):
        self.n_components = n_components
        self.linear_discriminants = None

    def select_LD(self,X,y):
        SW, SB=self.fit(X,y)
        A=np.linalg.inv(SW).dot(SB)
        eigenvalues,eigenvectors=np.linalg.eig(A)
        eigenvectors=eigenvectors.T
        idxs = np.argsort(abs(eigenvalues))[::-1]
        eigenvalues = eigenvalues[idxs]
        eigenvectors = eigenvectors[idxs]
        self.linear_discriminants = eigenvectors[0 : self.n_components] 

        eig_pairs = [(np.abs(eigenvalues[i]), eigenvectors[:,i], i) for i in range(len(eigenvalues))]

        eig_pairs.sort(key=lambda x: x[0], reverse=True) 
        return eigenvalues, eig_pairs
        
    def select_n_components_based_on_variance(self, X, y, var):
        eig_vals, eig_p = self.select_LD(X,y)
        tot = sum(eig_vals)
        var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]
        cum_var_exp = np.cumsum(var_exp)
        cum_var_exp = list(cum_var_exp)
        for i in cum_var_exp:
            if var > i:
                continue
            else:
                return cum_var_exp.index(i) + 1

    def fit(self, X, y):
        n_features = X.shape[1]
        class_labels = np.unique(y)
        mean_overall = np.mean(X, axis=0)
        SW = np.zeros((n_features, n_features)) # Within Class Scatter Matrix
        SB = np.zeros((n_features, n_features)) # Between Class Scater Matrix
        for c in class_labels:
            X_c = X[y == c]
            mean_c = np.mean(X_c, axis=0)
            SW += (X_c - mean_c).T.dot((X_c - mean_c))
            n_c = X_c.shape[0]
            mean_diff = (mean_c - mean_overall).to_numpy().reshape(n_features, 1)
            SB += n_c * (mean_diff).dot(mean_diff.T)
        return SW, SB

    def transform(self, X):
        return np.dot(X, self.linear_discriminants.T)
    
    # ['carbon', 'hardness', 'strength', 'thick', 'width', 'len']

tr_new = train_attributes.loc[:, ['carbon', 'hardness', 'strength', 'thick', 'width', 'len']]
val_new = val_attributes.loc[:, ['carbon', 'hardness', 'strength', 'thick', 'width', 'len']]
test_new = test_attributes.loc[:, ['carbon', 'hardness', 'strength', 'thick', 'width', 'len']]

lda = LDA(2)
lda.select_LD(tr_new, train_classes)
lda.select_LD(val_new, val_classes)
lda.select_LD(test_new, test_classes)

new_tr = lda.transform(tr_new)
new_val = lda.transform(val_new)
new_test = lda.transform(test_new)

new_tr

new_val

new_test

"""A function that will automatically select the number of linear discriminants based upon the percentage of variance that needs to be conserved"""

print(lda.select_n_components_based_on_variance(tr_new, train_classes, 96))

"""Perform PCA and compare the results with LDA"""

rfc_lda = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)
rfc_lda.fit(new_tr, train_classes)
y_pred_rfc_val_alda = rfc_lda.predict(new_val)
y_pred_rfc_test_alda = rfc_lda.predict(new_test)

print("CASE of LDA for Random Forest Classifier: \n")
print("For Validation data: ", cross_val_score(rfc_lda, new_val, val_classes, 5))
print("For Test data: ", cross_val_score(rfc_lda, new_test, test_classes, 5))

dtc_lda = DecisionTreeClassifier(max_depth=10, random_state=0)
dtc_lda.fit(new_tr, train_classes)
y_pred_dtc_val_alda = dtc_lda.predict(new_val)
y_pred_dtc_test_alda = dtc_lda.predict(new_test)

print("CASE of LDA for Decision Tree Classifier: \n")
print("For Validation data: ", cross_val_score(dtc_lda, new_val, val_classes, 5))
print("For Test data: ", cross_val_score(dtc_lda, new_test, test_classes, 5))

bc_lda = BaggingClassifier(n_estimators=100, max_samples=0.5, max_features=0.5, random_state=0)
bc_lda.fit(new_tr, train_classes)
y_pred_bc_val_alda = bc_lda.predict(new_val)
y_pred_bc_test_alda = bc_lda.predict(new_test)

print("CASE of LDA for Bagging Classifier: \n")
print("For Validation data: ", cross_val_score(bc_lda, new_val, val_classes, 5))
print("For Test data: ", cross_val_score(bc_lda, new_test, test_classes, 5))

"""Identify features having a high impact on classification tasks using both PCA and LDA and visualize the sample space using the first two principal components and first two linear discriminants and comment your observations"""

print("For PCA, earlier we found out that the feature values for which the eigen value had the maximum value of variance were the features :\n")
print("carbon", "with Eigen value = ", eig_pairs[0][0])
print("thick", "with Eigen value = ", eig_pairs[1][0])
print("width", "with Eigen value = ", eig_pairs[2][0])
print("len", "with Eigen value = ", eig_pairs[3][0])

print("For LDA, earlier we found out that the feature values for which the eigen value had the maximum value of variance were the features :\n")

a, b = lda.select_LD(tr_new, train_classes)

print("Feature Number",b[0][2], "with Eigen value = ", b[0][0])
print("Feature Number",b[1][2], "with Eigen value = ", b[1][0])

"""Using any 2 classification techniques make a 2 * 2 table with column headers as classification techniques used and row headers as feature extraction methods used.The values inside the table should be the accuracy achieved in each case. Compare the results of the table."""

print("For the Validation Data: \n")
new_df_val = pd.DataFrame(columns = ['Decision Tree', 'Bagging Classifier'])
new_df_val.loc[len(new_df_val)] = [accuracy_score(y_pred_dtc_val_apca, val_classes), accuracy_score(y_pred_bc_val_apca, val_classes)]
new_df_val.loc[len(new_df_val)] = [accuracy_score(y_pred_dtc_val_alda, val_classes), accuracy_score(y_pred_bc_val_alda, val_classes)]
new_df_val.index = ['PCA', 'LDA']
new_df_val

print("For the Testing Data: \n")
new_df_test = pd.DataFrame(columns = ['Decision Tree', 'Bagging Classifier'])
new_df_test.loc[len(new_df_test)] = [accuracy_score(y_pred_dtc_test_apca, test_classes), accuracy_score(y_pred_bc_test_apca, test_classes)]
new_df_test.loc[len(new_df_test)] = [accuracy_score(y_pred_dtc_test_alda, test_classes), accuracy_score(y_pred_bc_test_alda, test_classes)]
new_df_test.index = ['PCA', 'LDA']
new_df_test

print("For the Validation Data Cross Val Scores are: ", cross_val_score(dtc_lda, new_val, val_classes, 5))
print("For the Testing Data Cross Val Scores are: ", cross_val_score(dtc_lda, new_test, test_classes, 5))

"""Using LDA as a classifier, perform 5-fold cross-validation and plot ROC and compute AUC for each fold from scratch"""

from sklearn.metrics import roc_curve, auc
def plotting_ROC_computing_AUC(y_test, y_pred):
    n_classes = len(np.unique(y_test))
    fpr = dict()
    tpr = dict()
    roc_auc = dict()
    for i in range(n_classes):
        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])
        roc_auc[i] = auc(fpr[i], tpr[i])

    # Plot of a ROC curve for a specific class
    for i in range(n_classes):
        plt.figure()
        plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])
        plt.plot([0, 1], [0, 1], 'k--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver operating characteristic example')
        plt.legend(loc="lower right")
        plt.show()

# plotting_ROC_computing_AUC(test_classes, y_pred_dtc_test_alda)

"""                                THANK YOU"""